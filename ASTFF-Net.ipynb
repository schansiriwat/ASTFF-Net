{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers import LSTM, AveragePooling1D, Conv1D, Reshape, MaxPooling1D, GlobalAveragePooling1D, ZeroPadding1D\n",
    "from tensorflow.keras.layers import Dense, Flatten,concatenate\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "nClass=11\n",
    "w=7\n",
    "h=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_3(w,h,nClass):\n",
    "    input_layer1 = Input(shape=(w,h))\n",
    "    \n",
    "    input_layer2 = Input(shape=(w,h))\n",
    "    conv2 = ZeroPadding1D(padding=1)(input_layer2)\n",
    "    conv2 = Conv1D(filters=1024,kernel_size=3,strides=1)(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    add = concatenate([input_layer2,input_layer1])\n",
    "    dense = BatchNormalization()(add)\n",
    "    dense = GlobalAveragePooling1D()(dense)\n",
    "    dense = Dense(1024,activation='relu')(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    output_layer = Dense(nClass, activation='softmax')(dense)\n",
    "    model = Model(inputs=[input_layer1,input_layer2], outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba99cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel2Input(X1_train,X2_train, X1_test, X2_test, y_train, y_test,epochs,model,fileModel):\n",
    "    learning_rate = 0.01\n",
    "    decays = learning_rate/epochs\n",
    "    #decays = learning_rate*math.pow(drop,math.floor((1+epochs)/epochs_drop))\n",
    "    #decays=1e-6\n",
    "   # decays = 0.001\n",
    "    opt = SGD(lr=learning_rate, decay=decays, momentum=0.9, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',min_lr=0.001,factor=0.1,patience=5)\n",
    "    checkpointer = ModelCheckpoint(filepath=fileModel, verbose=1, save_best_only=True)\n",
    "\n",
    "    history=model.fit([X1_train,X2_train], y_train, batch_size=32, epochs=epochs,\n",
    "                                  validation_data=([X1_test,X2_test], y_test), verbose=1,\n",
    "                                  callbacks=[reduce_lr,checkpointer])\n",
    "    print(\"Evaluate model on test data\")\n",
    "    results = model.evaluate([X1_test,X2_test], y_test, batch_size=32)\n",
    "    print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportAcc(y_train,y_test,X1_test,X2_test,model):\n",
    "    y_trainc = np.argmax(y_train,axis=1)\n",
    "    y_testc = np.argmax(y_test,axis=1)\n",
    "    y_predc = np.argmax(model.predict([X1_test,X2_test]),axis=1)\n",
    "    print(accuracy_score(y_testc, y_predc)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_(dataFile):\n",
    "    \n",
    "    x = np.load(dataFile)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def loadLabel_():\n",
    "    \n",
    "    labelFile = \"feature_food100cut/label_food100.npy\"\n",
    "    y = np.load(labelFile)\n",
    "\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y,size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureConv1D = \"feature_food100cut/feature_food100_conv1d.npy\"\n",
    "featureLSTM = \"feature_food100cut/feature_food100_lstm.npy\"\n",
    "\n",
    "xDataFatureConv1D = loadData_(featureConv1D)\n",
    "xDataFatureLSTM = loadData_(featureLSTM)\n",
    "yLabel = loadLabel_()\n",
    "xConv1D_train, xConv1D_test, y_train, y_test = split_data(xDataFatureConv1D,yLabel,0.1)\n",
    "xLSTM_train, xLSTM_test, y_train, y_test = split_data(xDataFatureLSTM,yLabel,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7892c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileModel = 'model/food100_astffB3.hdf5'\n",
    "model=Model_3(w,h,nClass)\n",
    "fitModel2Input(xConv1D_train,xLSTM_train, xConv1D_test, xLSTM_test, y_train, y_test,epochs,model,fileModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a151be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileModel = 'model/food100_astffB3.hdf5'\n",
    "model = load_model(fileModel)\n",
    "reportAcc(y_train,y_test,xConv1D_test,xLSTM_test,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
