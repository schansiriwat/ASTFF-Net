{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, LSTM, AveragePooling1D, Conv1D, Reshape, BatchNormalization, Activation, Dropout, Add,MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, GlobalAveragePooling1D,GlobalMaxPooling1D,ZeroPadding1D,Concatenate\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf9dcf",
   "metadata": {},
   "source": [
    "# Load spatial feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x,y):\n",
    "    x = np.load(x)\n",
    "    y = np.load(y)\n",
    "    return x,y\n",
    "\n",
    "def split_data(x,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588924a7",
   "metadata": {},
   "source": [
    "# Conv1D+LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_(n_classes,w,h):\n",
    "    input_layer = Input(shape=(w,h))\n",
    "    #padding = BatchNormalization()(input_layer)\n",
    "    padding = ZeroPadding1D(padding=1)(input_layer)\n",
    "    conv1 = Conv1D(filters=1024,kernel_size=3,strides=1)(padding)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = AveragePooling1D(pool_size=2, strides = 2)(conv1)\n",
    "    lstm1 = LSTM(1024, dropout=0.2, recurrent_dropout=0.2,return_sequences=True)(pool1)\n",
    "    lstm1 = Dropout(0.2)(lstm1)\n",
    "    lstm1 = GlobalAveragePooling1D()(lstm1)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(lstm1)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba805c4",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(X_train, X_test, y_train, y_test,modelFile,epochs):\n",
    "    opt = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',min_lr=0.001,factor=0.1,patience=2)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath=modelFile,monitor='val_loss',save_best_only=True)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "                                  validation_data=(X_test, y_test), verbose=1,\n",
    "                                  callbacks=[reduce_lr,checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706dd10",
   "metadata": {},
   "source": [
    "# Train with Food11 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "nClasses = 11\n",
    "epochs = 10\n",
    "\n",
    "SOR_DATASET = 'feature_food11'\n",
    "SOR_LABEL = 'feature_food11'\n",
    "DES_MODEL_FILE = 'model'\n",
    "\n",
    "dataFile = SOR_DATASET+\"/feature_food11_ResNet50.npy\"\n",
    "labelFile = SOR_LABEL+\"/label_food11.npy\"\n",
    "\n",
    "modelFile = DES_MODEL_FILE+\"/model_conv1d_lstm_food11.hdf5\"\n",
    "\n",
    "x,y = load_data(dataFile,labelFile)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(x,y)\n",
    "\n",
    "model=Model_(nClasses,x.shape[1],x.shape[2])\n",
    "\n",
    "fitModel(X_train, X_test, y_train, y_test,modelFile,epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
